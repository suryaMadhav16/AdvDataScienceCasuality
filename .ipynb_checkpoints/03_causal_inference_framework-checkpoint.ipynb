{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045d9fc8",
   "metadata": {},
   "source": [
    "# Understanding Causal Inference with IHDP: From Theory to Practice - Part 3\n",
    "\n",
    "## 3. The Causal Inference Framework: A Systematic Approach\n",
    "\n",
    "### 3.1 Formulating the Causal Question\n",
    "\n",
    "> üìã **Step 1**: Define what causal effect you want to estimate\n",
    "\n",
    "Causal inference begins with a clear formulation of the causal question. For the IHDP dataset, our primary question is:\n",
    "\n",
    "**\"What is the effect of specialist home visits (treatment) on the cognitive test scores (outcome) of premature infants?\"**\n",
    "\n",
    "To formalize this question, we need to define:\n",
    "\n",
    "1. **Treatment variable (T)**: Binary indicator for receiving home visits\n",
    "2. **Outcome variable (Y)**: Cognitive test scores\n",
    "3. **Covariates (X)**: Baseline characteristics that may influence treatment assignment or outcomes\n",
    "4. **Target population**: Premature infants with low birth weight\n",
    "5. **Causal estimand**: The specific causal quantity we want to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc33baaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal Question Components:\n",
      "Treatment variable: treatment\n",
      "Outcome variable: y_factual\n",
      "Number of covariates: 25\n",
      "Target estimand: Average Treatment Effect (ATE)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load the IHDP dataset (assuming the function from Part 2)\n",
    "def load_ihdp_data():\n",
    "    \"\"\"\n",
    "    Load the IHDP dataset for causal inference\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with treatment, outcome, and covariates\n",
    "    \"\"\"\n",
    "    # Create a directory for the data if it doesn't exist\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    \n",
    "    # Download the data if it doesn't exist\n",
    "    if not os.path.exists('data/ihdp_npci_1.csv'):\n",
    "        print(\"Downloading IHDP dataset...\")\n",
    "        import urllib.request\n",
    "        url = \"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/IHDP/csv/ihdp_npci_1.csv\"\n",
    "        urllib.request.urlretrieve(url, 'data/ihdp_npci_1.csv')\n",
    "    \n",
    "    # Load the data\n",
    "    data = pd.read_csv('data/ihdp_npci_1.csv')\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    column_names = ['treatment']\n",
    "    column_names.extend([f'y_{i}' for i in range(2)])  # factual and counterfactual outcomes\n",
    "    column_names.extend([f'mu_{i}' for i in range(2)])  # expected outcomes without noise\n",
    "    column_names.extend([f'x_{i}' for i in range(25)])  # covariates\n",
    "    \n",
    "    data.columns = column_names\n",
    "    \n",
    "    # Rename for more intuitive understanding\n",
    "    data.rename(columns={\n",
    "        'y_0': 'y_factual',\n",
    "        'y_1': 'y_cfactual',\n",
    "        'mu_0': 'mu_0',\n",
    "        'mu_1': 'mu_1'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load the IHDP dataset\n",
    "ihdp_data = load_ihdp_data()\n",
    "\n",
    "# Define our causal question components\n",
    "treatment_var = 'treatment'\n",
    "outcome_var = 'y_factual'\n",
    "covariate_vars = [f'x_{i}' for i in range(25)]\n",
    "true_effect_var = 'mu_1 - mu_0'  # The true causal effect (available in this synthetic dataset)\n",
    "\n",
    "# Print our causal question components\n",
    "print(\"Causal Question Components:\")\n",
    "print(f\"Treatment variable: {treatment_var}\")\n",
    "print(f\"Outcome variable: {outcome_var}\")\n",
    "print(f\"Number of covariates: {len(covariate_vars)}\")\n",
    "print(f\"Target estimand: Average Treatment Effect (ATE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326445ab",
   "metadata": {},
   "source": [
    "#### Common Causal Estimands\n",
    "\n",
    "In causal inference, we typically focus on several key estimands:\n",
    "\n",
    "1. **Average Treatment Effect (ATE)**: The expected difference in outcomes if the entire population were treated versus if none were treated.\n",
    "   $$ ATE = E[Y(1) - Y(0)] $$\n",
    "\n",
    "2. **Average Treatment Effect on the Treated (ATT)**: The average effect for those who actually received the treatment.\n",
    "   $$ ATT = E[Y(1) - Y(0) | T=1] $$\n",
    "\n",
    "3. **Conditional Average Treatment Effect (CATE)**: The average treatment effect conditional on specific covariate values.\n",
    "   $$ CATE(x) = E[Y(1) - Y(0) | X=x] $$\n",
    "\n",
    "For the IHDP dataset, we'll primarily focus on the ATE, but we'll also explore heterogeneous treatment effects (CATE) across different subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd4b8bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ATE: 4.0166\n",
      "True ATT: 4.0030\n",
      "Naive ATE estimate (simple difference in means): 4.0272\n",
      "Bias in naive estimate: 0.0105\n"
     ]
    }
   ],
   "source": [
    "# Calculate the true ATE from our data\n",
    "true_ate = ihdp_data['mu_1'].mean() - ihdp_data['mu_0'].mean()\n",
    "\n",
    "# Calculate the true ATT\n",
    "true_att = ihdp_data.loc[ihdp_data['treatment'] == 1, 'mu_1'].mean() - \\\n",
    "           ihdp_data.loc[ihdp_data['treatment'] == 1, 'mu_0'].mean()\n",
    "\n",
    "# Calculate a naive estimate (simple difference in means)\n",
    "naive_ate = ihdp_data.loc[ihdp_data['treatment'] == 1, 'y_factual'].mean() - \\\n",
    "            ihdp_data.loc[ihdp_data['treatment'] == 0, 'y_factual'].mean()\n",
    "\n",
    "print(f\"True ATE: {true_ate:.4f}\")\n",
    "print(f\"True ATT: {true_att:.4f}\")\n",
    "print(f\"Naive ATE estimate (simple difference in means): {naive_ate:.4f}\")\n",
    "print(f\"Bias in naive estimate: {naive_ate - true_ate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a077aa",
   "metadata": {},
   "source": [
    "The naive estimate differs from the true ATE due to selection bias in the dataset. This demonstrates why we need proper causal inference methods to obtain accurate estimates.\n",
    "\n",
    "### 3.2 Causal Graph Modeling\n",
    "\n",
    "> üìä **Step 2**: Model the causal relationships between variables\n",
    "\n",
    "Causal graphs (Directed Acyclic Graphs or DAGs) are a powerful tool for representing causal relationships. They help us identify which variables to control for and which to avoid controlling for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5ddcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's install the required packages if not already installed\n",
    "# !pip install -q graphviz pydot pygraphviz\n",
    "# !pip install -q causalgraphicalmodels\n",
    "\n",
    "# Now let's create a basic causal graph for the IHDP dataset\n",
    "from cgraphicalmodels import CausalGraphicalModel\n",
    "# Define a simple causal graph\n",
    "# For simplicity, we'll group covariates into categories\n",
    "nodes = ['Covariates', 'Treatment', 'Outcome']\n",
    "edges = [\n",
    "    ('Covariates', 'Treatment'),\n",
    "    ('Covariates', 'Outcome'),\n",
    "    ('Treatment', 'Outcome')\n",
    "]\n",
    "\n",
    "# Create and visualize the causal graph\n",
    "causal_graph = CausalGraphicalModel(nodes=nodes, edges=edges)\n",
    "\n",
    "# Display the graph\n",
    "try:\n",
    "    causal_graph.draw()\n",
    "except Exception as e:\n",
    "    print(f\"Could not draw graph due to: {e}\")\n",
    "    print(\"Please ensure graphviz is correctly installed for visualization.\")\n",
    "    print(\"The graph structure consists of:\")\n",
    "    for edge in edges:\n",
    "        print(f\"  {edge[0]} -> {edge[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c7c8e",
   "metadata": {},
   "source": [
    "#### Types of Variables in Causal Inference\n",
    "\n",
    "When constructing causal graphs, we categorize variables based on their roles:\n",
    "\n",
    "1. **Confounders**: Variables that affect both treatment assignment and outcome\n",
    "2. **Mediators**: Variables on the causal pathway from treatment to outcome\n",
    "3. **Colliders**: Variables affected by both treatment and outcome\n",
    "4. **Instrumental Variables**: Variables that affect treatment but not outcome directly\n",
    "5. **Effect Modifiers**: Variables that interact with treatment to influence the outcome\n",
    "\n",
    "For the IHDP dataset, most of the covariates are potential confounders. Understanding these roles helps us decide which variables to include in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's identify which variables might be important confounders\n",
    "# We'll measure the association between each covariate and both treatment and outcome\n",
    "\n",
    "# Calculate correlations\n",
    "corr_with_treatment = {}\n",
    "corr_with_outcome = {}\n",
    "\n",
    "for cov in covariate_vars:\n",
    "    # For binary treatment, we use point-biserial correlation (equivalent to Pearson for binary)\n",
    "    corr_with_treatment[cov] = np.corrcoef(ihdp_data[treatment_var], ihdp_data[cov])[0, 1]\n",
    "    corr_with_outcome[cov] = np.corrcoef(ihdp_data[outcome_var], ihdp_data[cov])[0, 1]\n",
    "\n",
    "# Convert to DataFrame for easier visualization\n",
    "confounders_df = pd.DataFrame({\n",
    "    'Covariate': covariate_vars,\n",
    "    'Corr_with_Treatment': [corr_with_treatment[cov] for cov in covariate_vars],\n",
    "    'Corr_with_Outcome': [corr_with_outcome[cov] for cov in covariate_vars],\n",
    "    'Potential_Confounder': [abs(corr_with_treatment[cov]) > 0.1 and abs(corr_with_outcome[cov]) > 0.1 \n",
    "                             for cov in covariate_vars]\n",
    "})\n",
    "\n",
    "# Sort by strength of confounding (product of absolute correlations)\n",
    "confounders_df['Confounding_Strength'] = abs(confounders_df['Corr_with_Treatment']) * \\\n",
    "                                          abs(confounders_df['Corr_with_Outcome'])\n",
    "confounders_df = confounders_df.sort_values('Confounding_Strength', ascending=False)\n",
    "\n",
    "# Display the top potential confounders\n",
    "print(\"Top Potential Confounders:\")\n",
    "print(confounders_df.head(10))\n",
    "\n",
    "# Visualize the correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(confounders_df['Corr_with_Treatment'], \n",
    "            confounders_df['Corr_with_Outcome'],\n",
    "            s=100, alpha=0.7)\n",
    "\n",
    "# Add labels for top confounders\n",
    "for i, row in confounders_df.head(5).iterrows():\n",
    "    plt.annotate(row['Covariate'], \n",
    "                 (row['Corr_with_Treatment'], row['Corr_with_Outcome']),\n",
    "                 xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.title('Correlation of Covariates with Treatment and Outcome')\n",
    "plt.xlabel('Correlation with Treatment')\n",
    "plt.ylabel('Correlation with Outcome')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94582165",
   "metadata": {},
   "source": [
    "**Analysis:** Variables in the upper right and lower left quadrants with larger magnitudes are the strongest confounders, as they have strong correlations with both treatment and outcome. These variables are crucial to control for in our causal analysis.\n",
    "\n",
    "### 3.3 Identification Strategy\n",
    "\n",
    "> üîç **Step 3**: Identify assumptions needed to estimate causal effects\n",
    "\n",
    "To move from association to causation, we need to make certain assumptions:\n",
    "\n",
    "#### Key Causal Assumptions\n",
    "\n",
    "1. **Unconfoundedness/Ignorability**: The potential outcomes are independent of treatment assignment given the observed covariates.\n",
    "   $$ (Y(0), Y(1)) \\perp T | X $$\n",
    "\n",
    "2. **Positivity/Overlap**: Every unit has a non-zero probability of receiving either treatment condition.\n",
    "   $$ 0 < P(T=1|X=x) < 1 \\text{ for all } x \\text{ with } P(X=x) > 0 $$\n",
    "\n",
    "3. **Stable Unit Treatment Value Assumption (SUTVA)**:\n",
    "   - No interference between units\n",
    "   - No hidden variations of treatments\n",
    "\n",
    "Let's check the positivity assumption for the IHDP dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate propensity scores to check the positivity assumption\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit a logistic regression model to estimate propensity scores\n",
    "propensity_model = LogisticRegression(max_iter=1000)\n",
    "propensity_model.fit(ihdp_data[covariate_vars], ihdp_data[treatment_var])\n",
    "\n",
    "# Predict propensity scores\n",
    "ihdp_data['propensity_score'] = propensity_model.predict_proba(ihdp_data[covariate_vars])[:, 1]\n",
    "\n",
    "# Plot the distribution of propensity scores for treated and control groups\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=ihdp_data, x='propensity_score', hue=treatment_var, \n",
    "             bins=30, alpha=0.5, element=\"step\", common_norm=False)\n",
    "plt.title('Propensity Score Distributions')\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(['Control', 'Treated'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for extreme propensity scores\n",
    "extreme_propensity = (ihdp_data['propensity_score'] < 0.05) | (ihdp_data['propensity_score'] > 0.95)\n",
    "print(f\"Percentage of units with extreme propensity scores: {100 * extreme_propensity.mean():.2f}%\")\n",
    "\n",
    "# Check for the overlap assumption\n",
    "treated_min = ihdp_data.loc[ihdp_data[treatment_var] == 1, 'propensity_score'].min()\n",
    "treated_max = ihdp_data.loc[ihdp_data[treatment_var] == 1, 'propensity_score'].max()\n",
    "control_min = ihdp_data.loc[ihdp_data[treatment_var] == 0, 'propensity_score'].min()\n",
    "control_max = ihdp_data.loc[ihdp_data[treatment_var] == 0, 'propensity_score'].max()\n",
    "\n",
    "print(f\"Treated group propensity range: [{treated_min:.4f}, {treated_max:.4f}]\")\n",
    "print(f\"Control group propensity range: [{control_min:.4f}, {control_max:.4f}]\")\n",
    "\n",
    "# Common support region\n",
    "common_support_min = max(treated_min, control_min)\n",
    "common_support_max = min(treated_max, control_max)\n",
    "print(f\"Common support region: [{common_support_min:.4f}, {common_support_max:.4f}]\")\n",
    "print(f\"Percentage of units in common support: {100 * ((ihdp_data['propensity_score'] >= common_support_min) & (ihdp_data['propensity_score'] <= common_support_max)).mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b2fe1a",
   "metadata": {},
   "source": [
    "**Analysis:** The propensity score distributions show the probability of receiving treatment given covariates. Overlap between treated and control groups suggests the positivity assumption is reasonable, but areas with little overlap may lead to less reliable causal estimates.\n",
    "\n",
    "#### From Causal to Statistical Estimand\n",
    "\n",
    "Once we've established our causal assumptions, we need to translate our causal estimand (ATE) into a statistical estimand that can be estimated from observed data.\n",
    "\n",
    "Under the unconfoundedness assumption, the ATE can be estimated as:\n",
    "\n",
    "$$ ATE = E[Y(1) - Y(0)] = E_X[E[Y|T=1, X] - E[Y|T=0, X]] $$\n",
    "\n",
    "This forms the basis for many causal inference methods.\n",
    "\n",
    "### 3.4 Estimation Methods\n",
    "\n",
    "> ‚öôÔ∏è **Step 4**: Implement estimation strategies\n",
    "\n",
    "Various methods can be used to estimate causal effects. We'll categorize them into several groups:\n",
    "\n",
    "#### 1. Regression-Based Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd613e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple regression adjustment\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# We'll use a simple linear regression model\n",
    "reg_model = LinearRegression()\n",
    "\n",
    "# Add interaction terms between treatment and covariates\n",
    "X = ihdp_data[covariate_vars].copy()\n",
    "X['treatment'] = ihdp_data[treatment_var]\n",
    "\n",
    "# Add interaction terms for first few covariates (for simplicity)\n",
    "for cov in covariate_vars[:5]:  # Just use first 5 covariates for interactions\n",
    "    X[f'{cov}_x_treatment'] = X[cov] * X['treatment']\n",
    "\n",
    "# Fit the model\n",
    "reg_model.fit(X, ihdp_data[outcome_var])\n",
    "\n",
    "# Get the treatment effect coefficient\n",
    "treatment_coef = reg_model.coef_[X.columns.get_loc('treatment')]\n",
    "print(f\"Estimated ATE using regression adjustment: {treatment_coef:.4f}\")\n",
    "print(f\"True ATE: {true_ate:.4f}\")\n",
    "print(f\"Bias: {treatment_coef - true_ate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a99b8f",
   "metadata": {},
   "source": [
    "#### 2. Propensity Score Methods\n",
    "\n",
    "Propensity score methods estimate the probability of treatment given covariates, then use these scores to adjust for confounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0034e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already estimated propensity scores above\n",
    "\n",
    "# 2.1 Inverse Probability Weighting (IPW)\n",
    "# Calculate IPW weights\n",
    "ihdp_data['ipw'] = np.where(\n",
    "    ihdp_data[treatment_var] == 1,\n",
    "    1 / ihdp_data['propensity_score'],\n",
    "    1 / (1 - ihdp_data['propensity_score'])\n",
    ")\n",
    "\n",
    "# Trim extreme weights\n",
    "q99 = np.percentile(ihdp_data['ipw'], 99)\n",
    "ihdp_data['ipw_trimmed'] = np.minimum(ihdp_data['ipw'], q99)\n",
    "\n",
    "# Calculate the IPW estimate\n",
    "ipw_ate = (ihdp_data[ihdp_data[treatment_var] == 1]['ipw_trimmed'] * ihdp_data[ihdp_data[treatment_var] == 1][outcome_var]).sum() / ihdp_data[ihdp_data[treatment_var] == 1]['ipw_trimmed'].sum() - \\\n",
    "          (ihdp_data[ihdp_data[treatment_var] == 0]['ipw_trimmed'] * ihdp_data[ihdp_data[treatment_var] == 0][outcome_var]).sum() / ihdp_data[ihdp_data[treatment_var] == 0]['ipw_trimmed'].sum()\n",
    "\n",
    "print(f\"Estimated ATE using IPW: {ipw_ate:.4f}\")\n",
    "print(f\"True ATE: {true_ate:.4f}\")\n",
    "print(f\"Bias: {ipw_ate - true_ate:.4f}\")\n",
    "\n",
    "# 2.2 Propensity Score Matching\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Match treated units to control units based on propensity scores\n",
    "treated_indices = ihdp_data[ihdp_data[treatment_var] == 1].index\n",
    "control_indices = ihdp_data[ihdp_data[treatment_var] == 0].index\n",
    "\n",
    "treated_ps = ihdp_data.loc[treated_indices, 'propensity_score'].values.reshape(-1, 1)\n",
    "control_ps = ihdp_data.loc[control_indices, 'propensity_score'].values.reshape(-1, 1)\n",
    "\n",
    "# Find nearest neighbor matches\n",
    "nn = NearestNeighbors(n_neighbors=1)\n",
    "nn.fit(control_ps)\n",
    "distances, indices = nn.kneighbors(treated_ps)\n",
    "\n",
    "# Get matched control indices\n",
    "matched_control_indices = control_indices[indices.flatten()]\n",
    "\n",
    "# Calculate treatment effect\n",
    "matched_ate = ihdp_data.loc[treated_indices, outcome_var].mean() - \\\n",
    "              ihdp_data.loc[matched_control_indices, outcome_var].mean()\n",
    "\n",
    "print(f\"Estimated ATE using propensity score matching: {matched_ate:.4f}\")\n",
    "print(f\"True ATE: {true_ate:.4f}\")\n",
    "print(f\"Bias: {matched_ate - true_ate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50999529",
   "metadata": {},
   "source": [
    "#### 3. Doubly Robust Methods\n",
    "\n",
    "Doubly robust methods combine outcome modeling and propensity score weighting, providing protection against misspecification of either model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033813f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Augmented Inverse Probability Weighting (AIPW)\n",
    "# First, we need outcome models for both treatment groups\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Split data into treated and control\n",
    "treated_data = ihdp_data[ihdp_data[treatment_var] == 1]\n",
    "control_data = ihdp_data[ihdp_data[treatment_var] == 0]\n",
    "\n",
    "# Fit outcome models for treated and control groups\n",
    "treated_model = LinearRegression()\n",
    "treated_model.fit(treated_data[covariate_vars], treated_data[outcome_var])\n",
    "\n",
    "control_model = LinearRegression()\n",
    "control_model.fit(control_data[covariate_vars], control_data[outcome_var])\n",
    "\n",
    "# Predict potential outcomes for all units\n",
    "ihdp_data['y_pred_1'] = treated_model.predict(ihdp_data[covariate_vars])\n",
    "ihdp_data['y_pred_0'] = control_model.predict(ihdp_data[covariate_vars])\n",
    "\n",
    "# Calculate AIPW estimator\n",
    "treated_correction = (ihdp_data[treatment_var] * (ihdp_data[outcome_var] - ihdp_data['y_pred_1'])) / ihdp_data['propensity_score']\n",
    "control_correction = ((1 - ihdp_data[treatment_var]) * (ihdp_data[outcome_var] - ihdp_data['y_pred_0'])) / (1 - ihdp_data['propensity_score'])\n",
    "\n",
    "aipw_ate = (ihdp_data['y_pred_1'] - ihdp_data['y_pred_0']).mean() + treated_correction.mean() - control_correction.mean()\n",
    "\n",
    "print(f\"Estimated ATE using AIPW: {aipw_ate:.4f}\")\n",
    "print(f\"True ATE: {true_ate:.4f}\")\n",
    "print(f\"Bias: {aipw_ate - true_ate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a11fa7",
   "metadata": {},
   "source": [
    "#### 4. Machine Learning-Based Methods\n",
    "\n",
    "Machine learning methods can capture complex relationships between variables without requiring parametric assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f587d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using a simple ML-based approach: T-Learner\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# T-Learner: Fit separate models for treated and control groups\n",
    "t_treated_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "t_treated_model.fit(treated_data[covariate_vars], treated_data[outcome_var])\n",
    "\n",
    "t_control_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "t_control_model.fit(control_data[covariate_vars], control_data[outcome_var])\n",
    "\n",
    "# Predict potential outcomes for all units\n",
    "ihdp_data['y_pred_t1'] = t_treated_model.predict(ihdp_data[covariate_vars])\n",
    "ihdp_data['y_pred_t0'] = t_control_model.predict(ihdp_data[covariate_vars])\n",
    "\n",
    "# Calculate T-Learner ATE\n",
    "t_learner_ate = (ihdp_data['y_pred_t1'] - ihdp_data['y_pred_t0']).mean()\n",
    "\n",
    "print(f\"Estimated ATE using T-Learner: {t_learner_ate:.4f}\")\n",
    "print(f\"True ATE: {true_ate:.4f}\")\n",
    "print(f\"Bias: {t_learner_ate - true_ate:.4f}\")\n",
    "\n",
    "# Example of a more advanced method: Causal Forest (requires econml or causalml)\n",
    "# For illustration, we'll use causalml if available\n",
    "try:\n",
    "    from causalml.inference.tree import CausalForestDML\n",
    "    from sklearn.linear_model import LassoCV\n",
    "    \n",
    "    # Initialize the Causal Forest\n",
    "    cf = CausalForestDML(\n",
    "        model_y=LassoCV(),\n",
    "        model_t=LogisticRegression(max_iter=1000),\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    cf.fit(X=ihdp_data[covariate_vars], \n",
    "           treatment=ihdp_data[treatment_var],\n",
    "           y=ihdp_data[outcome_var])\n",
    "    \n",
    "    # Get treatment effects\n",
    "    cf_te = cf.effect(X=ihdp_data[covariate_vars])\n",
    "    cf_ate = cf_te.mean()\n",
    "    \n",
    "    print(f\"Estimated ATE using Causal Forest: {cf_ate:.4f}\")\n",
    "    print(f\"True ATE: {true_ate:.4f}\")\n",
    "    print(f\"Bias: {cf_ate - true_ate:.4f}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"causalml package not available. Skipping Causal Forest example.\")\n",
    "    print(\"To install: pip install causalml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d6137",
   "metadata": {},
   "source": [
    "### 3.5 Evaluation and Validation\n",
    "\n",
    "> üìè **Step 5**: Assess the quality of causal estimates\n",
    "\n",
    "Evaluating causal estimates is challenging because we usually can't observe the ground truth. However, in the IHDP dataset, we have the advantage of knowing the true causal effects.\n",
    "\n",
    "Let's compare different methods using several metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b615017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to compare methods\n",
    "methods = [\n",
    "    'Naive (Difference in Means)',\n",
    "    'Regression Adjustment',\n",
    "    'IPW',\n",
    "    'Propensity Score Matching',\n",
    "    'AIPW',\n",
    "    'T-Learner (RF)'\n",
    "]\n",
    "\n",
    "estimates = [\n",
    "    naive_ate,\n",
    "    treatment_coef,\n",
    "    ipw_ate,\n",
    "    matched_ate,\n",
    "    aipw_ate,\n",
    "    t_learner_ate\n",
    "]\n",
    "\n",
    "if 'cf_ate' in locals():  # If we ran the Causal Forest\n",
    "    methods.append('Causal Forest')\n",
    "    estimates.append(cf_ate)\n",
    "\n",
    "# Calculate metrics\n",
    "biases = [est - true_ate for est in estimates]\n",
    "abs_biases = [abs(bias) for bias in biases]\n",
    "rel_biases = [abs(bias / true_ate) * 100 for bias in biases]\n",
    "\n",
    "# Create the comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Method': methods,\n",
    "    'ATE Estimate': estimates,\n",
    "    'Bias': biases,\n",
    "    'Absolute Bias': abs_biases,\n",
    "    'Relative Bias (%)': rel_biases\n",
    "})\n",
    "\n",
    "# Sort by absolute bias\n",
    "comparison_df = comparison_df.sort_values('Absolute Bias')\n",
    "\n",
    "# Print comparison\n",
    "print(\"Comparison of Causal Inference Methods:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualize the comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(y=comparison_df['Method'], width=comparison_df['ATE Estimate'], color='skyblue')\n",
    "plt.axvline(x=true_ate, color='red', linestyle='--', label=f'True ATE = {true_ate:.4f}')\n",
    "plt.xlabel('ATE Estimate')\n",
    "plt.title('Comparison of ATE Estimates from Different Methods')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d764e0",
   "metadata": {},
   "source": [
    "**Analysis:** This comparison shows how different causal inference methods perform. Methods with lower bias provide estimates closer to the true ATE. In practice, where the true effect is unknown, we'd rely on theoretical properties of the methods and sensitivity analysis.\n",
    "\n",
    "#### Sensitivity Analysis\n",
    "\n",
    "Sensitivity analysis helps assess how robust our estimates are to violations of key assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb56a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple sensitivity analysis for unobserved confounding\n",
    "# We'll simulate the impact of an unobserved confounder with varying strength\n",
    "\n",
    "def sensitivity_analysis(effect_estimate, n_sims=50, max_confounder_strength=0.5):\n",
    "    \"\"\"\n",
    "    Perform a simple sensitivity analysis for unobserved confounding\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    effect_estimate: float\n",
    "        The estimated treatment effect\n",
    "    n_sims: int\n",
    "        Number of simulation points\n",
    "    max_confounder_strength: float\n",
    "        Maximum strength of confounding to simulate\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame with sensitivity results\n",
    "    \"\"\"\n",
    "    confounder_strengths = np.linspace(0, max_confounder_strength, n_sims)\n",
    "    adjusted_estimates = []\n",
    "    \n",
    "    for strength in confounder_strengths:\n",
    "        # Simple linear adjustment for an unobserved confounder\n",
    "        adjusted_est = effect_estimate - strength\n",
    "        adjusted_estimates.append(adjusted_est)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Confounder_Strength': confounder_strengths,\n",
    "        'Adjusted_Estimate': adjusted_estimates\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Let's apply sensitivity analysis to our best estimate (whichever had lowest bias)\n",
    "best_method_idx = comparison_df['Absolute Bias'].idxmin()\n",
    "best_method = comparison_df.loc[best_method_idx, 'Method']\n",
    "best_estimate = comparison_df.loc[best_method_idx, 'ATE Estimate']\n",
    "\n",
    "sensitivity_results = sensitivity_analysis(best_estimate, n_sims=100)\n",
    "\n",
    "# Plot the sensitivity analysis\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sensitivity_results['Confounder_Strength'], \n",
    "         sensitivity_results['Adjusted_Estimate'],\n",
    "         color='blue', linewidth=2)\n",
    "plt.axhline(y=true_ate, color='red', linestyle='--', \n",
    "            label=f'True ATE = {true_ate:.4f}')\n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Find where the adjusted estimate crosses zero\n",
    "if min(sensitivity_results['Adjusted_Estimate']) < 0 < max(sensitivity_results['Adjusted_Estimate']):\n",
    "    zero_crossing = np.interp(0, sensitivity_results['Adjusted_Estimate'][::-1], \n",
    "                            sensitivity_results['Confounder_Strength'][::-1])\n",
    "    plt.axvline(x=zero_crossing, color='green', linestyle=':', \n",
    "                label=f'Sign change at strength = {zero_crossing:.4f}')\n",
    "\n",
    "plt.title(f'Sensitivity Analysis for {best_method}')\n",
    "plt.xlabel('Unobserved Confounder Strength')\n",
    "plt.ylabel('Adjusted Treatment Effect Estimate')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"The estimate from {best_method} would change sign if there was an unobserved confounder with strength greater than {zero_crossing:.4f}\" if 'zero_crossing' in locals() else f\"The estimate from {best_method} would not change sign even with a strong unobserved confounder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76016923",
   "metadata": {},
   "source": [
    "**Analysis:** The sensitivity analysis shows how the estimated treatment effect would change if there were an unobserved confounder of varying strength. When the adjusted estimate crosses zero, it indicates how strong an unobserved confounder would need to be to change the direction of the estimated effect.\n",
    "\n",
    "## Resources and References\n",
    "\n",
    "- Pearl, J. (2009). Causality: Models, Reasoning, and Inference. Cambridge University Press.\n",
    "- Hern√°n, M. A., & Robins, J. M. (2020). Causal Inference: What If. Chapman & Hall/CRC.\n",
    "- Hill, J. L. (2011). Bayesian nonparametric modeling for causal inference. Journal of Computational and Graphical Statistics.\n",
    "- [DoWhy: A Library for Causal Inference](https://microsoft.github.io/dowhy/)\n",
    "- [EconML: A Library for ML-Based Causal Inference](https://github.com/microsoft/EconML)\n",
    "- [CausalML: A Library for Uplift Modeling and Causal Inference](https://github.com/uber/causalml)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "getting-started-llmops",
   "language": "python",
   "name": "getting-started-llmops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

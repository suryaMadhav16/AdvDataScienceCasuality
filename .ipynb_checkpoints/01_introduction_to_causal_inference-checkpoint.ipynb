{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031bb831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9b1fc52",
   "metadata": {},
   "source": [
    "# Understanding Causal Inference with IHDP: From Theory to Practice - Part 1\n",
    "\n",
    "## 1. Introduction to Causal Inference\n",
    "\n",
    "### 1.1 The Need for Causal Inference\n",
    "![XKCD Comic](https://imgs.xkcd.com/comics/correlation_2x.png)\n",
    "<div class=\"key-concept\">\n",
    "  ⚠️ Key Concept: Correlation does not imply causation\n",
    "</div>\n",
    "\n",
    "In predictive modeling, we often focus on finding correlations between variables. However, for decision-making, we need to understand the *causal* relationship between actions and outcomes.\n",
    "\n",
    "The fundamental problem of causal inference is that we can never observe both potential outcomes for the same unit - we can't simultaneously observe what happens when a person receives a treatment and doesn't receive a treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa656b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate data to illustrate correlation vs causation\n",
    "n = 1000\n",
    "# Common cause (confounder)\n",
    "confounder = np.random.normal(0, 1, n)\n",
    "# Treatment influenced by confounder\n",
    "treatment = 0.7 * confounder + np.random.normal(0, 0.5, n)\n",
    "# Outcome influenced by both treatment and confounder\n",
    "outcome = 0.3 * treatment + 0.7 * confounder + np.random.normal(0, 0.5, n)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Treatment': treatment,\n",
    "    'Outcome': outcome,\n",
    "    'Confounder': confounder\n",
    "})\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Treatment vs Outcome (shows correlation)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(data['Treatment'], data['Outcome'], alpha=0.5)\n",
    "# Fit a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(data[['Treatment']], data['Outcome'])\n",
    "# Add regression line\n",
    "x_range = np.linspace(data['Treatment'].min(), data['Treatment'].max(), 100)\n",
    "plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), 'r-', linewidth=2)\n",
    "plt.title('Correlation: Treatment vs Outcome\\nCorrelation = {:.2f}'.format(\n",
    "    np.corrcoef(data['Treatment'], data['Outcome'])[0, 1]))\n",
    "plt.xlabel('Treatment')\n",
    "plt.ylabel('Outcome')\n",
    "\n",
    "# Plot 2: Treatment vs Outcome with confounder as color\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(data['Treatment'], data['Outcome'], c=data['Confounder'], cmap='viridis', alpha=0.5)\n",
    "plt.colorbar(label='Confounder')\n",
    "plt.title('Causal Structure: Treatment, Outcome, and Confounder')\n",
    "plt.xlabel('Treatment')\n",
    "plt.ylabel('Outcome')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a7a6b5",
   "metadata": {},
   "source": [
    "**Analysis:** The first plot shows a strong correlation between treatment and outcome, which might lead us to conclude that the treatment causes the outcome. However, the second plot reveals that the confounder influences both treatment and outcome. When we condition on the confounder (shown by color), we see that the true causal effect of treatment on outcome is much weaker than the correlation suggests.\n",
    "\n",
    "### 1.2 Real-World Applications\n",
    "\n",
    "Causal inference is crucial in various domains:\n",
    "\n",
    "#### Healthcare\n",
    "- Evaluating treatment effectiveness\n",
    "- Understanding disease progression\n",
    "- Personalizing medical decisions\n",
    "\n",
    "#### Policy\n",
    "- Program evaluation\n",
    "- Social interventions assessment\n",
    "- Education policy design\n",
    "\n",
    "#### Business\n",
    "- Marketing strategy optimization\n",
    "- Product feature evaluations\n",
    "- Customer retention strategies\n",
    "\n",
    "### 1.3 Key Concepts in Causal Inference\n",
    "\n",
    "#### The Potential Outcomes Framework\n",
    "\n",
    "Developed by Rubin, this framework formalizes causal inference through potential outcomes. For each unit i:\n",
    "- Y_i(1): Outcome if unit i receives treatment\n",
    "- Y_i(0): Outcome if unit i doesn't receive treatment\n",
    "\n",
    "The individual treatment effect is defined as:\n",
    "\n",
    "$$ \\tau_i = Y_i(1) - Y_i(0) $$\n",
    "\n",
    "However, we can only observe one of these outcomes for each unit, which is known as the **fundamental problem of causal inference**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e51b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple illustration of potential outcomes\n",
    "np.random.seed(42)\n",
    "n = 10  # Small sample for illustration\n",
    "\n",
    "# True treatment effects (not observable in real settings)\n",
    "true_effect = np.random.normal(5, 2, n)\n",
    "\n",
    "# Potential outcomes\n",
    "potential_outcomes = pd.DataFrame({\n",
    "    'Unit': range(1, n+1),\n",
    "    'Y(0)': np.random.normal(10, 3, n),                # Control outcome\n",
    "    'Y(1)': np.random.normal(10, 3, n) + true_effect,  # Treated outcome\n",
    "    'True_Effect': true_effect\n",
    "})\n",
    "\n",
    "# Randomly assign treatment\n",
    "potential_outcomes['Treatment'] = np.random.binomial(1, 0.5, n)\n",
    "\n",
    "# Observed outcomes (we only see one potential outcome per unit)\n",
    "potential_outcomes['Observed_Y'] = np.where(\n",
    "    potential_outcomes['Treatment'] == 1,\n",
    "    potential_outcomes['Y(1)'],\n",
    "    potential_outcomes['Y(0)']\n",
    ")\n",
    "\n",
    "print(\"Potential Outcomes Framework Illustration:\")\n",
    "print(potential_outcomes)\n",
    "\n",
    "# What we can actually observe in real data\n",
    "observed_data = potential_outcomes[['Unit', 'Treatment', 'Observed_Y']].copy()\n",
    "print(\"\\nWhat we actually observe in real data:\")\n",
    "print(observed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e8c382",
   "metadata": {},
   "source": [
    "#### Types of Treatment Effects\n",
    "\n",
    "**Average Treatment Effect (ATE):**\n",
    "The average effect of the treatment across the entire population.\n",
    "\n",
    "$$ ATE = E[Y(1) - Y(0)] $$\n",
    "\n",
    "**Conditional Average Treatment Effect (CATE):**\n",
    "The average effect of the treatment conditional on specific covariates.\n",
    "\n",
    "$$ CATE(X=x) = E[Y(1) - Y(0) | X=x] $$\n",
    "\n",
    "**Average Treatment Effect on the Treated (ATT):**\n",
    "The average effect among those who received the treatment.\n",
    "\n",
    "$$ ATT = E[Y(1) - Y(0) | T=1] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d5178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the different treatment effects\n",
    "ate_true = potential_outcomes['True_Effect'].mean()\n",
    "att_true = potential_outcomes.loc[potential_outcomes['Treatment'] == 1, 'True_Effect'].mean()\n",
    "\n",
    "# Naive estimate (just comparing treated and control groups)\n",
    "naive_ate = potential_outcomes.loc[potential_outcomes['Treatment'] == 1, 'Observed_Y'].mean() - \\\n",
    "            potential_outcomes.loc[potential_outcomes['Treatment'] == 0, 'Observed_Y'].mean()\n",
    "\n",
    "print(f\"True ATE: {ate_true:.2f}\")\n",
    "print(f\"True ATT: {att_true:.2f}\")\n",
    "print(f\"Naive ATE estimate: {naive_ate:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e253704",
   "metadata": {},
   "source": [
    "### 1.4 Key Assumptions in Causal Inference\n",
    "\n",
    "1. **Unconfoundedness (Ignorability)**: Treatment assignment is independent of potential outcomes given observed covariates.\n",
    "   \n",
    "   $$ (Y(0), Y(1)) \\perp T | X $$\n",
    "\n",
    "2. **Positivity (Overlap)**: Every unit has a non-zero probability of receiving either treatment or control.\n",
    "   \n",
    "   $$ 0 < P(T=1|X=x) < 1 \\text{ for all } x $$\n",
    "\n",
    "3. **Stable Unit Treatment Value Assumption (SUTVA)**:\n",
    "   - No interference: One unit's treatment doesn't affect another unit's outcome\n",
    "   - No hidden variations of treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2febe7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the overlap assumption\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "# Create two features\n",
    "X1 = np.random.normal(0, 1, n)\n",
    "X2 = np.random.normal(0, 1, n)\n",
    "\n",
    "# Scenario 1: Good overlap\n",
    "p_good = 1 / (1 + np.exp(-(0.5 * X1)))\n",
    "treatment_good = np.random.binomial(1, p_good, n)\n",
    "\n",
    "# Scenario 2: Poor overlap\n",
    "p_poor = 1 / (1 + np.exp(-(3 * X1 + 2 * X2)))\n",
    "treatment_poor = np.random.binomial(1, p_poor, n)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Good overlap\n",
    "axes[0].scatter(X1, X2, c=treatment_good, cmap='coolwarm', alpha=0.6)\n",
    "axes[0].set_title('Good Overlap')\n",
    "axes[0].set_xlabel('X1')\n",
    "axes[0].set_ylabel('X2')\n",
    "\n",
    "# Poor overlap\n",
    "axes[1].scatter(X1, X2, c=treatment_poor, cmap='coolwarm', alpha=0.6)\n",
    "axes[1].set_title('Poor Overlap (Positivity Violation)')\n",
    "axes[1].set_xlabel('X1')\n",
    "axes[1].set_ylabel('X2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9c4424",
   "metadata": {},
   "source": [
    "**Analysis:** The plots illustrate the positivity assumption. In the \"Good Overlap\" scenario, both treated (red) and control (blue) units exist across the entire covariate space. In the \"Poor Overlap\" scenario, there are regions with only treated or only control units, making it impossible to estimate treatment effects in those regions without extrapolation.\n",
    "\n",
    "## Resources and References\n",
    "\n",
    "- [Causal Inference: What If](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/) by Hernán & Robins\n",
    "- [The Book of Why](http://bayes.cs.ucla.edu/WHY/) by Judea Pearl\n",
    "- [Causal Inference for The Brave and True](https://matheusfacure.github.io/python-causality-handbook/landing-page.html) - Python-focused tutorial\n",
    "- [DoWhy Library Documentation](https://py-why.github.io/dowhy/)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "getting-started-llmops",
   "language": "python",
   "name": "getting-started-llmops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
